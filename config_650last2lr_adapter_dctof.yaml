fix_seed: 0
checkpoints_every: 16
result_path: ./results_650last2lr_lora_dctof
config_path: ./config_650last2lr_lora_dctof.yaml

resume:
  resume: False
  resume_path: path/to/checkpoints.pth
  restart_optimizer: True

encoder:
  composition: official_esm_v2 # esm_v2, promprot, both
  model_type: official_esm_v2 # esm_v2, t5
  model_name:  esm2_t6_8M_UR50D # facebook/esm2_t33_650M_UR50D, facebook/esm2_t30_150M_UR50D, facebook/esm2_t12_35M_UR50D, facebook/esm2_t6_8M_UR50D, Rostlab/prot_t5_base_mt_uniref50
  max_len: 602  #602
  num_classes: 8
  prm4prmpro: ppi
  frag_overlap: 200

PEFT: lora # FT, PFT, frozen, lora, PromT

train_settings:
  num_epochs: 30
  shuffle: True
  device: cuda
  batch_size: 16
  grad_accumulation: 1
  loss_pos_weight: 20


valid_settings:
  do_every: 1
  batch_size: 16
  device: cuda
  cutoff: 0.5

optimizer:
  name: adam
  lr: 1e-4
  weight_decouple: True
  weight_decay: 1e-3
  eps: 1e-16
  beta_1: 0.9
  beta_2: 0.999
  use_8bit_adam: False
  grad_clip_norm: 1
  decay:
    warmup: 1024
    min_lr: 1e-5
    gamma: 0.2
    num_restarts: 1